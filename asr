1.1. o que é hadoop?
sistema em processamento de dados distribuido
uma infraestrutura de rede de computadores trabalhando em conjunto (cluster)

1.2. qual a finalidade do hadoop?
processar grandes volumes de dados em batch

1.3. quais o 2 elementos principais do hadoop?
map reduce e hdfs

1.4. o que o map reduce faz?
processamento

1.5. o que é o hdfs?
sistemas de arquivos distribuido

1.6. qual a analogia do hadoop?
imagine que voce precisa construir uma casa, 1 pedreiro levaria 1 ano, um super pedreiro levaria 11 meses, ao inves disso eu contrato 5 pedreiros trabalhando em parelelo coordenado por uma engenheiro levando 3 meses para construção

1.7. dentro analogia da construção o que acontecia antes quando se precisava de mais capacidade de processamento?
contratava-se um super pedreiro, porem existia limites fisicos para esse aumento

1.8. qual era a solução para limites fisicos de processamento?
colocava-se varios servidores trabalhando em conjunto

1.9. dentro da analogia da construção o que é master e slaves?
master - engenheiros
slaves - pedreiros

1.10 em qual linguagem o hadoop foi criado?
foi criado em java

1.11 quem criou o hive?
o facebook

1.12 o que programação imperativa?
especificação das etapas para atingir o objetivo, como fazer 

1.13 o que programação declarativa?
especificação do objetivos, o que fazer

1.14 qual o modelo de programação o hadoop apresenta?
programação imperativa

1.15 em qual arquitetura o hive é baseado?
baseado na arquitetura map reduce / hdfs

1.16 com quais tipos de dados o hive trabalha e qual sistema é semelhante?
dados estruturados, semelhante a um bd relacional

1.17 qual linguagem de programação hive utiliza?
sql

1.18 o que o hive é parecido com um dw?
é uma armazem de dados distribuido sobre map reduce/hdfs

1.19 que tipo de sistema de processamento de dados o hadoop é, transacional ou analitico?
analitico

1.20 o que é o apache impala?
uma alternativa para sql em hadoop, com engine do hive sobre mapreduce

1.21 qual o objetivo do impala?
ser mais rapido que o hive padrao (com engine MR)

1.22 qual a caracteristica do impala em consultas medias?
menor latencia e melhor desempenho

1.23 em qual sql o impala é baseado?
o do hive

1.24 o que o hive veio solucionar em relação ao hadoop
facilitar as consultas pois utiliza sql, o hadoop utiliza java

2.1 quais os principais componentes do hive?
meta store, hiveserver2, mysql, hive client

2.2 o que é armazenado no metastore do hive?
metadados, informações de tabela(bd, tipo de dados, views e etc)

2.3 que componente usamos para acessar o hive?
o hive client

2.4 o que é hcatalog?
é o catalogo do hive, armazena metadados

2.5 onde ficam os metadados do hive?
ficam no hcatalog

2.6 qual banco de dados por padrao ficam os metadados do hive
hcatalog usando o bd mysql por padrao

2.7 qual é o motor de execução (execution engine) por padrao do hive?
map reduce

2.8 quais as alternativas de motor de execução ao hive?
tez, spark

2.9 o que é schema on read?
a definição dos metadados podem ser definida na leitura dos dados

2.10 quais caracteristicas diferentes de um banco de dados que o hive tem em tabelas?
apontam para um arquivo no hdfs
podem estar em diferente formatos
um mesmo arquivo pode pertencer a diferente tabelas
um arquivo pode ser manipulado por outra aplicação
apagar a tabela apaga os metadados, não os arquivos

2.11 quando apagamos uma tabela no hive o que acontece?
apagamos o metadados nao o arquivo

2.12 os arquivos do hive tem quais formatos?
diferentes formatos

2.13 arquivos no hive pode pertencer a quais tabelas?
diferente tabelas

2.14 o que sao os bancos de dados do hive?
sao um conjunto de tabelas definidos em um schema

2.15 Os arquivos do banco de dados do hive, são exclusivos?
nao, pq o mesmo arquivo pode estar em diferentes tabelas em diferentes bancos de dados

2.16 fisicamente qual é o padrao de path do banco de dados?
/user/hive/warehouse

2.17 onde estao as principais configurações do hive?
hive-site.xml

2.18 para qual uso é o shell do beeline?
alterar configurações do hive ex set hive.default.fileformat = Orc, hive.default.fileformat.managed = Orc

2.19 quais sao as 4 categorias de configuração do hive?
configuration variables
metastore configuration variables
configuration variables do hadoop
run time information

12.1 Quais os principais tipos de tabela que hive tem?
external e internal

12.2 qual tipo de tabela que temos quando o hive nao controla o arquivo?
external

12.3 qual tipo de tabela que temos quando o acesso exclusivo pelo hive?
internal

12.4 qual tipo de tabela que temos quando excluir a tabela exlui o arquivo fisico?
internal

12.5 quando nos conectamos ao hive, por padrao qual o banco de dados que ele se conecta?
default

12.6 qual o comando para mudar de banco de dados do hive para o banco LOCACAO
USE LOCACAO;

12.7 como criar uma tabela externa chamada CLIENTES com esses requisitos:
colunas 
(idcliente int
cnh string
cpf string
validade date
nome string
datacadastro date
datanascimento date
telefone string
status string)
a linha deve ter a delimitação de , (virgula) e deve ser armazenado com textfile
e deve ser carregado de um path do hdfs dentro da table CLIENTES;

CREATE EXTERNAL TABLE CLIENTES (idcliente int,
cnh string,
cpf string,
validade date,
nome string,
datacadastro date,
datanascimento date,
telefone string,
status string) row format delimited fields terminated by ','  STORED AS TEXTFILE;
LOAD DATA INPATH 'opt/hive/locacao/clientes.csv' INTO TABLE CLIENTES;
SELECT * FROM CLIENTES;

12.8 o que faz a propriedade de tabela imutable?
nao permite mais inserir dados

12.9 qual é a propriedade de tabela que faz a compressao no formato orc?
orc.compress

12.10 o que faz a o propriedade de tabela skip.header.line.count?
ignora linhas iniciais (cabeçalhos)

13.1 como criar um diretorio no hdfs
hdfs dfs -mkdir <diretorio>

13.2 como copiar um arquivo de fora do container para o container
docker cp arquivos hive4:/opt/hive/arquivos

13.3 como copiar todos os arquivos csv usando hdfs para outra pasta
hdfs dfs -put <file> <dir>

13.4 como mostrar banco de dados do hive
show databases;

13.5 como deletar uma banco de dados com tabelas dentro
drop database <nome banco> cascade;

13.6 como se conectar ao beeline atraves do start hive cli?
/opt/hive/bin/hive
!connect jdbc:hive2://localhost:10000/

14.1 crie uma tabela veiculos e faça a carga com o csv chamado veiculos que está no path do hdfs /opt/hive/locacao/veiculos.csv
create external table veiculos (idveiculo int, dataaquisicao date, ano int, modelo string, placa string, status string, diaria double) 
row format delimited fields terminated by ',' stored as textfile;
LOAD DATA INPATH '/opt/hive/locacao/veiculos.csv' INTO TABLE VEICULOS;

15.1 como descrever os metadados da tabela no hive, forma simples e detalhada
describe <tabela>, describe formatted <locacao>;

15.2 como descrever os metadados da tabela com as informacoes do banco de dados
describe database <locacao>;

15.3 o banco default do hive existe fisicamente?
nao, apenas logicamente

15.4 como consultar no hcatalog os bancos de dados escritos no metadados
select * from dbs;

15.5 qual é a tabela do mysql quem tem as tabelas do hive, faça o comando para selecionar ela
select * from tbls where db_id=10;

18.1 o que é o hive?
The Apache Hive ™ is a distributed, fault-tolerant data warehouse system that enables analytics at a massive scale and facilitates reading, writing, and managing petabytes of data residing in distributed storage using SQL.


27.1 como carregar dados do sistema de arquivos local para o hive?
LOAD DATA LOCAL INPATH '/home/diegodila/arquivo.csv' INTO TABLE CLIENTES;

27.2 como criar uma tabela no hive a partir de outra tabela?
create table locacao2 as select * from locacao where iddespachante = 2;

27.3 como fazer um insert em outro banco de dados?
create database teste;
create table teste.locacao 2 as select * from locacao where iddespachante = 2;
use teste;
select total from locacao2;
drop database teste cascade;

27.4 Como start o banco de dados postgres no docker
docker exec -it docker-hive-hive-metastore-postgresql-1 psql -U postgres
docker exec -it docker-hive-hive-metastore-postgresql-1 sh ;  psql --username postgres ; SELECT datname FROM pg_catalog.pg_database;

27.5 como localizar as pastas disponiveis no hdfs?
hdfs dfs -ls /

30.1 o sqoop é uma ferramenta de qual ecossistema?
hadoop

30.2 o que é sqoop?
é uma ferramenta para importação de dados rdbms

30.3 como que o sqoop importa os dados?
atraves de um drive jdbc, importa de diferente banco de dados usando a mesma ferramenta por abstração

30.4 quantas tarefas o sqoop cria em paralelo por padrao para importar dados
4

30.5 como o sqoop dividi as tarefas para importação de dados?
usando a chave primaria

30.6 quando surge novos registros, o sqoop da suporte? e como?
modo incremental usando o append para tabela que tem inclusao de novos registros

30.7 como funciona o lastmodified do sqoop?
ele uitliza o um timestamp no registros para verificar quais dados precisam de atualizaçao

30.8


